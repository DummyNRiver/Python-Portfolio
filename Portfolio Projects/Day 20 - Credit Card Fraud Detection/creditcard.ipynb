{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8602f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, f1_score, precision_score, recall_score, fbeta_score, precision_recall_curve, make_scorer, fbeta_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40c0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\jaraneses\\OneDrive - 2X LLC\\Codes\\Portfolio Projects_storage\\Day 20 - Credit Card Fraud Detection\\creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92029050",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4480c357",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630d4f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6179e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (20, 20))\n",
    "sns.heatmap(df.corr(), annot = True, cmap = 'coolwarm', fmt ='.2f')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed66c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No correlation seen in V with each other, (V is an anonymized PCA). Focus more on correlation of each V to time, amount, and class.\n",
    "corr = df.corr()\n",
    "focus_column = ['Time', 'Amount', 'Class']\n",
    "v_features = [f'V{i}' for i in range(1, 29)]\n",
    "\n",
    "v_corr = corr.loc[v_features, focus_column]\n",
    "\n",
    "v_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4469ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "sns.heatmap(v_corr, annot= True, fmt = '.2f', cmap='RdYlBu')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e4c702",
   "metadata": {},
   "source": [
    "Strongest correlations with Fraud (Class)\n",
    "\n",
    "V17: -0.326 (Strong negative) → Lower V17 = Higher fraud risk\n",
    "\n",
    "V14: -0.303 (Strong negative) → Lower V14 = Higher fraud risk\n",
    "\n",
    "V12: -0.261 (Strong negative) → Lower V12 = Higher fraud risk\n",
    "\n",
    "V10: -0.217 (Moderate negative) → Lower V10 = Higher fraud risk\n",
    "\n",
    "V16: -0.197 (Moderate negative) → Lower V16 = Higher fraud risk\n",
    "\n",
    "V3:  -0.193 (Moderate negative) → Lower V3 = Higher fraud risk\n",
    "\n",
    "V7:  -0.187 (Moderate negative) → Lower V7 = Higher fraud risk\n",
    "\n",
    "Time \n",
    "\n",
    "V3:  -0.420 (Strong negative) → Later times = Lower V3\n",
    "\n",
    "V25: -0.233 (Moderate negative) → Later times = Lower V25\n",
    "\n",
    "V11: -0.248 (Moderate negative) → Later times = Lower V11\n",
    "\n",
    "Amount\n",
    "\n",
    "V2:  -0.531 (Very strong negative) → Higher amounts = Lower V2\n",
    "\n",
    "V20: +0.339 (Strong positive) → Higher amounts = Higher V20\n",
    "\n",
    "V7:  +0.397 (Strong positive) → Higher amounts = Higher V7\n",
    "\n",
    "V5:  -0.386 (Strong negative) → Higher amounts = Lower V5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c540e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Class.value_counts()\n",
    "\n",
    "# Massive class imbalance, use AUPRC instead of accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9e86ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = 'Class')\n",
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a1cda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaafcab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(random_state= 2, max_iter=2000),\n",
    "        'params': {\n",
    "            'C': [0.001, 0.0001],\n",
    "            'class_weight': [{0: 1, 1: 100}, {0: 1, 1: 500}, {0: 1, 1: 1000}],\n",
    "            'solver': ['liblinear']\n",
    "        }\n",
    "    },\n",
    "    'Random Forest':{\n",
    "        'model': RandomForestClassifier(random_state= 2),\n",
    "        'params': {\n",
    "            'n_estimators': [100],\n",
    "            'max_depth': [10, None],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [2, 4], \n",
    "            'class_weight': ['balanced']\n",
    "        }\n",
    "    },\n",
    "    'XGBoost':{\n",
    "        'model': XGBClassifier(random_state = 2),\n",
    "        'params': {\n",
    "            'max_depth': [3, 4],\n",
    "            'learning_rate': [0.01, 0.05],\n",
    "            'n_estimators': [200, 300],\n",
    "            'scale_pos_weight': [578, 100, 200],\n",
    "            'subsample': [0.8, 0.9],\n",
    "            'colsample_bytree': [0.8, 0.9]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c8a67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "all_models = {}\n",
    "\n",
    "f2_scorer = make_scorer(fbeta_score, beta=2, average='binary')\n",
    "\n",
    "for name, config in models.items():\n",
    "    grid_search = GridSearchCV(\n",
    "        config['model'],\n",
    "        config['params'],\n",
    "        cv = 3,\n",
    "        scoring = f2_scorer,\n",
    "        n_jobs= 1,\n",
    "        verbose = 1\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_scaled, y_train)\n",
    "    all_models[name] = grid_search.best_estimator_\n",
    "\n",
    "    train_pred = grid_search.best_estimator_.predict(X_train_scaled)\n",
    "    test_pred = grid_search.best_estimator_.predict(X_test_scaled)\n",
    "\n",
    "    \n",
    "    results[name] = {\n",
    "        'best_model': grid_search.best_estimator_,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'Train Accuracy': average_precision_score(y_train, train_pred),\n",
    "        'Test Accuracy': average_precision_score(y_test, test_pred),\n",
    "        'Train F2': fbeta_score(y_train, train_pred, beta = 2),\n",
    "        'Test F2': fbeta_score(y_test, test_pred, beta = 2),\n",
    "        'Precision': precision_score(y_test, test_pred),\n",
    "        'Recall': recall_score(y_test, test_pred)\n",
    "    }\n",
    "\n",
    "    best_model_name = max(results.keys(), key = lambda x: results[x]['Test F2'])\n",
    "    best_model = results[best_model_name]['best_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c2fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_data = []\n",
    "\n",
    "for name, result in results.items():\n",
    "    summary_data.append({\n",
    "        'Model': name,\n",
    "        'Train Accuracy': result['Train Accuracy'],\n",
    "        'Test Accuracy': result['Test Accuracy'],\n",
    "        'Train F2': result['Train F2'],\n",
    "        'Test F2': result['Test F2'],\n",
    "        'Precision': result['Precision'],\n",
    "        'Recall': result['Recall']\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df = summary_df.round(4)\n",
    "summary_df = summary_df.sort_values('Test F2', ascending= False).reset_index(drop = True)\n",
    "print(summary_df.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
